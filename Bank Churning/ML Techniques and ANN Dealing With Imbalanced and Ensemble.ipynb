{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abb5aac",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36a5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895ddff",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9d9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a806e72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e16790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc488f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exited'].value_counts()\n",
    "#print(Counter(df['Exited']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68743467",
   "metadata": {},
   "source": [
    "## The Data is a little bit imabalanced (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549f507",
   "metadata": {},
   "source": [
    "# Random Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b705b2",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eed8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"CustomerId\", axis=1, inplace=True)\n",
    "df.drop(\"Surname\", axis=1, inplace=True)\n",
    "#df.drop(\"HasCrCard\", axis=1, inplace=True)\n",
    "df.drop(\"RowNumber\", axis=1, inplace = True)\n",
    "# Take all Row, Take all column until -1\n",
    "X = df.iloc[:,:-1].values\n",
    "# Take all Row, Take only -1 column\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4740364c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7168d635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n"
     ]
    }
   ],
   "source": [
    "print(X[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08aa945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ebf8a",
   "metadata": {},
   "source": [
    "# Encoding Gender and One Hot Encoder for Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953fe94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb85c5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43809cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613babd",
   "metadata": {},
   "source": [
    "# Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b2e5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd300265",
   "metadata": {},
   "source": [
    "# Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42845540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83224d13",
   "metadata": {},
   "source": [
    "# Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94158ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a91ae7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before undersampling:  Counter({0: 6368, 1: 1632})\n"
     ]
    }
   ],
   "source": [
    "print(\"Before undersampling: \", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e77f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "552f7d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling:  Counter({0: 1632, 1: 1632})\n"
     ]
    }
   ],
   "source": [
    "print(\"After undersampling: \", Counter(y_train_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7837d92",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9cf72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91b64c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1109  486]\n",
      " [ 115  290]]\n",
      "0.6995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(random_state = 0)\n",
    "lr_clf.fit(X_train_under, y_train_under)\n",
    "y_lr_pred = lr_clf.predict(X_test)\n",
    "\n",
    "lr_cm = confusion_matrix(y_test, y_lr_pred)\n",
    "print(lr_cm)\n",
    "accuracy = accuracy_score(y_test, y_lr_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cec5b6",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48570821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1137  458]\n",
      " [ 112  293]]\n",
      "0.715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clknn = KNeighborsClassifier(n_neighbors = 5, metric='minkowski', p = 2)\n",
    "clknn.fit(X_train_under, y_train_under)\n",
    "y_clknn_pred = clknn.predict(X_test)\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, y_clknn_pred)\n",
    "print(cm_knn)\n",
    "accuracy_knn = accuracy_score(y_test, y_clknn_pred)\n",
    "print(accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2411d",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5931429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[910 685]\n",
      " [171 234]]\n",
      "0.572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(kernel = 'sigmoid', random_state = 0)\n",
    "clf_svm.fit(X_train_under, y_train_under)\n",
    "y_svm_pred = clf_svm.predict(X_test)\n",
    "\n",
    "cm_svm = confusion_matrix(y_test, y_svm_pred)\n",
    "print(cm_svm)\n",
    "accuracy_svm = accuracy_score(y_test, y_svm_pred)\n",
    "print(accuracy_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e92f9a",
   "metadata": {},
   "source": [
    "# Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48aeb674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1209  386]\n",
      " [  86  319]]\n",
      "0.764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_ksvm = SVC(kernel = 'rbf', random_state = 0)\n",
    "clf_ksvm.fit(X_train_under, y_train_under)\n",
    "y_ksvm_pred = clf_ksvm.predict(X_test)\n",
    "\n",
    "cm_ksvm = confusion_matrix(y_test, y_ksvm_pred)\n",
    "print(cm_ksvm)\n",
    "accuracy_ksvm = accuracy_score(y_test, y_ksvm_pred)\n",
    "print(accuracy_ksvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c1c058",
   "metadata": {},
   "source": [
    "# Naive Bayess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9abcd451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1140  455]\n",
      " [ 124  281]]\n",
      "0.7105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_gauss = GaussianNB()\n",
    "clf_gauss.fit(X_train_under, y_train_under)\n",
    "y_gauss_pred = clf_gauss.predict(X_test)\n",
    "\n",
    "cm_gauss = confusion_matrix(y_test, y_gauss_pred)\n",
    "print(cm_gauss)\n",
    "accuracy_gauss = accuracy_score(y_test, y_gauss_pred)\n",
    "print(accuracy_gauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4c696",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57a371ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1096  499]\n",
      " [ 109  296]]\n",
      "0.696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_tree = DecisionTreeClassifier(criterion = 'entropy')\n",
    "clf_tree.fit(X_train_under, y_train_under)\n",
    "y_tree_pred = clf_tree.predict(X_test)\n",
    "\n",
    "cm_tree = confusion_matrix(y_test, y_tree_pred)\n",
    "print(cm_tree)\n",
    "accuracy_tree = accuracy_score(y_test, y_tree_pred)\n",
    "print(accuracy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820240bf",
   "metadata": {},
   "source": [
    "# Bagging Decision Tree (Ensamble Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50432b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1233  362]\n",
      " [  88  317]]\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, max_samples=0.8, oob_score=True)\n",
    "bagging.fit(X_train_under, y_train_under)\n",
    "y_treeb_pred = bagging.predict(X_test)\n",
    "\n",
    "cm_treeb = confusion_matrix(y_test, y_treeb_pred)\n",
    "print(cm_treeb)\n",
    "accuracy_treeb = accuracy_score(y_test, y_treeb_pred)\n",
    "print(accuracy_treeb)\n",
    "#print(bagging.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9305b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699142156862745"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa4704",
   "metadata": {},
   "source": [
    "# Random Forest (Ensamble Forests of Randomized Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb3f1e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1232  363]\n",
      " [  84  321]]\n",
      "0.7765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_forest = RandomForestClassifier(n_estimators = 50, criterion = 'entropy')\n",
    "clf_forest.fit(X_train_under, y_train_under)\n",
    "y_forest_pred = clf_forest.predict(X_test)\n",
    "\n",
    "cm_forest = confusion_matrix(y_test, y_forest_pred)\n",
    "print(cm_forest)\n",
    "accuracy_forest = accuracy_score(y_test, y_forest_pred)\n",
    "print(accuracy_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f9dd9",
   "metadata": {},
   "source": [
    "# Voting Classifier (Ensamble Boosting Voting Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d23d6",
   "metadata": {},
   "source": [
    "# Use LogisticRegression, Naive, KNN, KernelSVM, RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26bb0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59b33484",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state = 1)\n",
    "clf2 = GaussianNB()\n",
    "clf3 = KNeighborsClassifier(n_neighbors = 5, metric='minkowski', p = 2)\n",
    "clf4 = SVC(kernel = 'rbf', random_state = 1)\n",
    "clf5 = RandomForestClassifier(n_estimators = 50, criterion = 'entropy', random_state = 1)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1),('gnb', clf2),('knn',clf3),('svc', clf4),('rf', clf5)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "335a758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.78 (+/- 0.00) [Naive Bayes]\n",
      "Accuracy: 0.77 (+/- 0.00) [KNN]\n",
      "Accuracy: 0.80 (+/- 0.00) [SVC]\n",
      "Accuracy: 0.86 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.80 (+/- 0.00) [Ensemble Voting]\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, eclf], ['Logistic Regression', 'Naive Bayes', 'KNN', 'SVC', 'Random Forest', 'Ensemble Voting']):\n",
    "    scores = cross_val_score(clf,X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e8c659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1192  403]\n",
      " [  84  321]]\n",
      "0.7565\n"
     ]
    }
   ],
   "source": [
    "eclf.fit(X_train_under, y_train_under)\n",
    "y_eclf_pred = eclf.predict(X_test)\n",
    "\n",
    "cm_eclf = confusion_matrix(y_test, y_eclf_pred)\n",
    "print(cm_eclf)\n",
    "accuracy_eclf = accuracy_score(y_test, y_eclf_pred)\n",
    "print(accuracy_eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45120b03",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03873ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "199e8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "411b26ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0159387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ccf0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "577c1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e08c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "102/102 [==============================] - 0s 696us/step - loss: 0.6966 - accuracy: 0.5797\n",
      "Epoch 2/200\n",
      "102/102 [==============================] - 0s 686us/step - loss: 0.6500 - accuracy: 0.6192\n",
      "Epoch 3/200\n",
      "102/102 [==============================] - 0s 592us/step - loss: 0.6318 - accuracy: 0.6428\n",
      "Epoch 4/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.6185 - accuracy: 0.6517\n",
      "Epoch 5/200\n",
      "102/102 [==============================] - 0s 601us/step - loss: 0.6063 - accuracy: 0.6630\n",
      "Epoch 6/200\n",
      "102/102 [==============================] - 0s 719us/step - loss: 0.5961 - accuracy: 0.6740\n",
      "Epoch 7/200\n",
      "102/102 [==============================] - 0s 618us/step - loss: 0.5877 - accuracy: 0.6854\n",
      "Epoch 8/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.5814 - accuracy: 0.6918\n",
      "Epoch 9/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.5761 - accuracy: 0.6982\n",
      "Epoch 10/200\n",
      "102/102 [==============================] - 0s 706us/step - loss: 0.5715 - accuracy: 0.7016\n",
      "Epoch 11/200\n",
      "102/102 [==============================] - 0s 687us/step - loss: 0.5667 - accuracy: 0.7037\n",
      "Epoch 12/200\n",
      "102/102 [==============================] - 0s 647us/step - loss: 0.5619 - accuracy: 0.7080\n",
      "Epoch 13/200\n",
      "102/102 [==============================] - 0s 794us/step - loss: 0.5566 - accuracy: 0.7108\n",
      "Epoch 14/200\n",
      "102/102 [==============================] - 0s 696us/step - loss: 0.5513 - accuracy: 0.7227\n",
      "Epoch 15/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.5460 - accuracy: 0.7227\n",
      "Epoch 16/200\n",
      "102/102 [==============================] - 0s 686us/step - loss: 0.5395 - accuracy: 0.7276\n",
      "Epoch 17/200\n",
      "102/102 [==============================] - 0s 584us/step - loss: 0.5323 - accuracy: 0.7353\n",
      "Epoch 18/200\n",
      "102/102 [==============================] - 0s 722us/step - loss: 0.5258 - accuracy: 0.7387\n",
      "Epoch 19/200\n",
      "102/102 [==============================] - 0s 653us/step - loss: 0.5192 - accuracy: 0.7451\n",
      "Epoch 20/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.5126 - accuracy: 0.7463\n",
      "Epoch 21/200\n",
      "102/102 [==============================] - 0s 677us/step - loss: 0.5064 - accuracy: 0.7528\n",
      "Epoch 22/200\n",
      "102/102 [==============================] - 0s 657us/step - loss: 0.5009 - accuracy: 0.7558\n",
      "Epoch 23/200\n",
      "102/102 [==============================] - 0s 608us/step - loss: 0.4959 - accuracy: 0.7613\n",
      "Epoch 24/200\n",
      "102/102 [==============================] - 0s 775us/step - loss: 0.4915 - accuracy: 0.7635\n",
      "Epoch 25/200\n",
      "102/102 [==============================] - 0s 716us/step - loss: 0.4878 - accuracy: 0.7647\n",
      "Epoch 26/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.4848 - accuracy: 0.7672\n",
      "Epoch 27/200\n",
      "102/102 [==============================] - 0s 707us/step - loss: 0.4825 - accuracy: 0.7678\n",
      "Epoch 28/200\n",
      "102/102 [==============================] - 0s 634us/step - loss: 0.4801 - accuracy: 0.7690\n",
      "Epoch 29/200\n",
      "102/102 [==============================] - 0s 725us/step - loss: 0.4784 - accuracy: 0.7708\n",
      "Epoch 30/200\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4766 - accuracy: 0.7739\n",
      "Epoch 31/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4753 - accuracy: 0.7745\n",
      "Epoch 32/200\n",
      "102/102 [==============================] - 0s 649us/step - loss: 0.4741 - accuracy: 0.7739\n",
      "Epoch 33/200\n",
      "102/102 [==============================] - 0s 681us/step - loss: 0.4726 - accuracy: 0.7727\n",
      "Epoch 34/200\n",
      "102/102 [==============================] - 0s 559us/step - loss: 0.4715 - accuracy: 0.7730\n",
      "Epoch 35/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4707 - accuracy: 0.7721\n",
      "Epoch 36/200\n",
      "102/102 [==============================] - 0s 569us/step - loss: 0.4700 - accuracy: 0.7757\n",
      "Epoch 37/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.4690 - accuracy: 0.7776\n",
      "Epoch 38/200\n",
      "102/102 [==============================] - 0s 693us/step - loss: 0.4683 - accuracy: 0.7782\n",
      "Epoch 39/200\n",
      "102/102 [==============================] - 0s 601us/step - loss: 0.4678 - accuracy: 0.7760\n",
      "Epoch 40/200\n",
      "102/102 [==============================] - 0s 716us/step - loss: 0.4677 - accuracy: 0.7760\n",
      "Epoch 41/200\n",
      "102/102 [==============================] - 0s 618us/step - loss: 0.4666 - accuracy: 0.7760\n",
      "Epoch 42/200\n",
      "102/102 [==============================] - 0s 698us/step - loss: 0.4658 - accuracy: 0.7760\n",
      "Epoch 43/200\n",
      "102/102 [==============================] - 0s 589us/step - loss: 0.4658 - accuracy: 0.7806\n",
      "Epoch 44/200\n",
      "102/102 [==============================] - 0s 689us/step - loss: 0.4652 - accuracy: 0.7760\n",
      "Epoch 45/200\n",
      "102/102 [==============================] - 0s 794us/step - loss: 0.4644 - accuracy: 0.7791\n",
      "Epoch 46/200\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.4639 - accuracy: 0.7776\n",
      "Epoch 47/200\n",
      "102/102 [==============================] - 0s 755us/step - loss: 0.4630 - accuracy: 0.7822\n",
      "Epoch 48/200\n",
      "102/102 [==============================] - 0s 804us/step - loss: 0.4635 - accuracy: 0.77850s - loss: 0.4731 - accuracy: 0.76\n",
      "Epoch 49/200\n",
      "102/102 [==============================] - 0s 784us/step - loss: 0.4632 - accuracy: 0.7767\n",
      "Epoch 50/200\n",
      "102/102 [==============================] - 0s 755us/step - loss: 0.4627 - accuracy: 0.7803\n",
      "Epoch 51/200\n",
      "102/102 [==============================] - 0s 706us/step - loss: 0.4616 - accuracy: 0.7797\n",
      "Epoch 52/200\n",
      "102/102 [==============================] - 0s 941us/step - loss: 0.4614 - accuracy: 0.7816\n",
      "Epoch 53/200\n",
      "102/102 [==============================] - 0s 775us/step - loss: 0.4610 - accuracy: 0.7812\n",
      "Epoch 54/200\n",
      "102/102 [==============================] - 0s 726us/step - loss: 0.4605 - accuracy: 0.7837\n",
      "Epoch 55/200\n",
      "102/102 [==============================] - 0s 676us/step - loss: 0.4595 - accuracy: 0.7825\n",
      "Epoch 56/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4600 - accuracy: 0.7816\n",
      "Epoch 57/200\n",
      "102/102 [==============================] - 0s 794us/step - loss: 0.4598 - accuracy: 0.7822\n",
      "Epoch 58/200\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4591 - accuracy: 0.7849\n",
      "Epoch 59/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.4589 - accuracy: 0.7831\n",
      "Epoch 60/200\n",
      "102/102 [==============================] - 0s 608us/step - loss: 0.4586 - accuracy: 0.7834\n",
      "Epoch 61/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4590 - accuracy: 0.7809\n",
      "Epoch 62/200\n",
      "102/102 [==============================] - 0s 531us/step - loss: 0.4580 - accuracy: 0.7828\n",
      "Epoch 63/200\n",
      "102/102 [==============================] - 0s 618us/step - loss: 0.4576 - accuracy: 0.7855\n",
      "Epoch 64/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.4578 - accuracy: 0.7852\n",
      "Epoch 65/200\n",
      "102/102 [==============================] - 0s 608us/step - loss: 0.4576 - accuracy: 0.7840\n",
      "Epoch 66/200\n",
      "102/102 [==============================] - 0s 647us/step - loss: 0.4570 - accuracy: 0.7846\n",
      "Epoch 67/200\n",
      "102/102 [==============================] - 0s 569us/step - loss: 0.4570 - accuracy: 0.7846\n",
      "Epoch 68/200\n",
      "102/102 [==============================] - 0s 647us/step - loss: 0.4568 - accuracy: 0.7825\n",
      "Epoch 69/200\n",
      "102/102 [==============================] - 0s 559us/step - loss: 0.4563 - accuracy: 0.7837\n",
      "Epoch 70/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4566 - accuracy: 0.7834\n",
      "Epoch 71/200\n",
      "102/102 [==============================] - 0s 784us/step - loss: 0.4562 - accuracy: 0.7840\n",
      "Epoch 72/200\n",
      "102/102 [==============================] - 0s 705us/step - loss: 0.4561 - accuracy: 0.7840\n",
      "Epoch 73/200\n",
      "102/102 [==============================] - 0s 589us/step - loss: 0.4555 - accuracy: 0.7868\n",
      "Epoch 74/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.4556 - accuracy: 0.7843\n",
      "Epoch 75/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.4556 - accuracy: 0.7837\n",
      "Epoch 76/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.4552 - accuracy: 0.7852\n",
      "Epoch 77/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.4547 - accuracy: 0.7840\n",
      "Epoch 78/200\n",
      "102/102 [==============================] - 0s 676us/step - loss: 0.4548 - accuracy: 0.7831\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 833us/step - loss: 0.4546 - accuracy: 0.7874\n",
      "Epoch 80/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.78 - 0s 765us/step - loss: 0.4546 - accuracy: 0.7849\n",
      "Epoch 81/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4546 - accuracy: 0.7865\n",
      "Epoch 82/200\n",
      "102/102 [==============================] - 0s 618us/step - loss: 0.4536 - accuracy: 0.7874\n",
      "Epoch 83/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4540 - accuracy: 0.7849\n",
      "Epoch 84/200\n",
      "102/102 [==============================] - 0s 549us/step - loss: 0.4539 - accuracy: 0.7862\n",
      "Epoch 85/200\n",
      "102/102 [==============================] - 0s 648us/step - loss: 0.4537 - accuracy: 0.7858\n",
      "Epoch 86/200\n",
      "102/102 [==============================] - 0s 572us/step - loss: 0.4537 - accuracy: 0.7886\n",
      "Epoch 87/200\n",
      "102/102 [==============================] - 0s 700us/step - loss: 0.4530 - accuracy: 0.7874\n",
      "Epoch 88/200\n",
      "102/102 [==============================] - 0s 629us/step - loss: 0.4532 - accuracy: 0.7834\n",
      "Epoch 89/200\n",
      "102/102 [==============================] - 0s 657us/step - loss: 0.4527 - accuracy: 0.7865\n",
      "Epoch 90/200\n",
      "102/102 [==============================] - 0s 539us/step - loss: 0.4529 - accuracy: 0.7874\n",
      "Epoch 91/200\n",
      "102/102 [==============================] - 0s 717us/step - loss: 0.4524 - accuracy: 0.7862\n",
      "Epoch 92/200\n",
      "102/102 [==============================] - 0s 695us/step - loss: 0.4519 - accuracy: 0.7904\n",
      "Epoch 93/200\n",
      "102/102 [==============================] - 0s 529us/step - loss: 0.4523 - accuracy: 0.7883\n",
      "Epoch 94/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.4521 - accuracy: 0.7837\n",
      "Epoch 95/200\n",
      "102/102 [==============================] - 0s 696us/step - loss: 0.4518 - accuracy: 0.7895\n",
      "Epoch 96/200\n",
      "102/102 [==============================] - 0s 608us/step - loss: 0.4515 - accuracy: 0.7874\n",
      "Epoch 97/200\n",
      "102/102 [==============================] - 0s 647us/step - loss: 0.4520 - accuracy: 0.7895\n",
      "Epoch 98/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4516 - accuracy: 0.7886\n",
      "Epoch 99/200\n",
      "102/102 [==============================] - 0s 686us/step - loss: 0.4513 - accuracy: 0.7871\n",
      "Epoch 100/200\n",
      "102/102 [==============================] - 0s 539us/step - loss: 0.4510 - accuracy: 0.7871\n",
      "Epoch 101/200\n",
      "102/102 [==============================] - 0s 647us/step - loss: 0.4509 - accuracy: 0.7880\n",
      "Epoch 102/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4511 - accuracy: 0.7889\n",
      "Epoch 103/200\n",
      "102/102 [==============================] - 0s 833us/step - loss: 0.4503 - accuracy: 0.7914\n",
      "Epoch 104/200\n",
      "102/102 [==============================] - 0s 579us/step - loss: 0.4507 - accuracy: 0.7889\n",
      "Epoch 105/200\n",
      "102/102 [==============================] - 0s 716us/step - loss: 0.4506 - accuracy: 0.7886\n",
      "Epoch 106/200\n",
      "102/102 [==============================] - 0s 569us/step - loss: 0.4505 - accuracy: 0.7892\n",
      "Epoch 107/200\n",
      "102/102 [==============================] - 0s 706us/step - loss: 0.4503 - accuracy: 0.7901\n",
      "Epoch 108/200\n",
      "102/102 [==============================] - 0s 618us/step - loss: 0.4504 - accuracy: 0.7892\n",
      "Epoch 109/200\n",
      "102/102 [==============================] - 0s 559us/step - loss: 0.4497 - accuracy: 0.7923\n",
      "Epoch 110/200\n",
      "102/102 [==============================] - 0s 618us/step - loss: 0.4498 - accuracy: 0.7871\n",
      "Epoch 111/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4498 - accuracy: 0.7904\n",
      "Epoch 112/200\n",
      "102/102 [==============================] - 0s 578us/step - loss: 0.4498 - accuracy: 0.7917\n",
      "Epoch 113/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4500 - accuracy: 0.7914\n",
      "Epoch 114/200\n",
      "102/102 [==============================] - 0s 775us/step - loss: 0.4491 - accuracy: 0.7907\n",
      "Epoch 115/200\n",
      "102/102 [==============================] - 0s 657us/step - loss: 0.4499 - accuracy: 0.7901\n",
      "Epoch 116/200\n",
      "102/102 [==============================] - 0s 657us/step - loss: 0.4496 - accuracy: 0.7895\n",
      "Epoch 117/200\n",
      "102/102 [==============================] - 0s 549us/step - loss: 0.4495 - accuracy: 0.7911\n",
      "Epoch 118/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.4496 - accuracy: 0.7907\n",
      "Epoch 119/200\n",
      "102/102 [==============================] - 0s 579us/step - loss: 0.4493 - accuracy: 0.7911\n",
      "Epoch 120/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4485 - accuracy: 0.7920\n",
      "Epoch 121/200\n",
      "102/102 [==============================] - 0s 716us/step - loss: 0.4495 - accuracy: 0.7904\n",
      "Epoch 122/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4493 - accuracy: 0.7895\n",
      "Epoch 123/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4488 - accuracy: 0.7904\n",
      "Epoch 124/200\n",
      "102/102 [==============================] - 0s 639us/step - loss: 0.4491 - accuracy: 0.7898\n",
      "Epoch 125/200\n",
      "102/102 [==============================] - 0s 655us/step - loss: 0.4493 - accuracy: 0.7911\n",
      "Epoch 126/200\n",
      "102/102 [==============================] - 0s 598us/step - loss: 0.4486 - accuracy: 0.7886\n",
      "Epoch 127/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4488 - accuracy: 0.7871\n",
      "Epoch 128/200\n",
      "102/102 [==============================] - 0s 529us/step - loss: 0.4486 - accuracy: 0.7898\n",
      "Epoch 129/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4483 - accuracy: 0.7917\n",
      "Epoch 130/200\n",
      "102/102 [==============================] - 0s 677us/step - loss: 0.4484 - accuracy: 0.7865\n",
      "Epoch 131/200\n",
      "102/102 [==============================] - 0s 716us/step - loss: 0.4482 - accuracy: 0.7898\n",
      "Epoch 132/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4484 - accuracy: 0.7904\n",
      "Epoch 133/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4482 - accuracy: 0.7917\n",
      "Epoch 134/200\n",
      "102/102 [==============================] - 0s 568us/step - loss: 0.4479 - accuracy: 0.7871\n",
      "Epoch 135/200\n",
      "102/102 [==============================] - 0s 676us/step - loss: 0.4479 - accuracy: 0.7917\n",
      "Epoch 136/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4480 - accuracy: 0.7901\n",
      "Epoch 137/200\n",
      "102/102 [==============================] - 0s 549us/step - loss: 0.4479 - accuracy: 0.7883\n",
      "Epoch 138/200\n",
      "102/102 [==============================] - 0s 559us/step - loss: 0.4479 - accuracy: 0.7883\n",
      "Epoch 139/200\n",
      "102/102 [==============================] - 0s 565us/step - loss: 0.4482 - accuracy: 0.7911\n",
      "Epoch 140/200\n",
      "102/102 [==============================] - 0s 678us/step - loss: 0.4475 - accuracy: 0.7898\n",
      "Epoch 141/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4481 - accuracy: 0.79170s - loss: 0.4500 - accuracy: 0.78\n",
      "Epoch 142/200\n",
      "102/102 [==============================] - 0s 686us/step - loss: 0.4479 - accuracy: 0.7904\n",
      "Epoch 143/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4481 - accuracy: 0.7898\n",
      "Epoch 144/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4481 - accuracy: 0.7901\n",
      "Epoch 145/200\n",
      "102/102 [==============================] - 0s 600us/step - loss: 0.4477 - accuracy: 0.7898\n",
      "Epoch 146/200\n",
      "102/102 [==============================] - 0s 686us/step - loss: 0.4478 - accuracy: 0.7883\n",
      "Epoch 147/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.4475 - accuracy: 0.7904\n",
      "Epoch 148/200\n",
      "102/102 [==============================] - 0s 715us/step - loss: 0.4473 - accuracy: 0.7898\n",
      "Epoch 149/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.4473 - accuracy: 0.7898\n",
      "Epoch 150/200\n",
      "102/102 [==============================] - 0s 559us/step - loss: 0.4475 - accuracy: 0.7874\n",
      "Epoch 151/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4474 - accuracy: 0.7898\n",
      "Epoch 152/200\n",
      "102/102 [==============================] - 0s 608us/step - loss: 0.4474 - accuracy: 0.7901\n",
      "Epoch 153/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.4479 - accuracy: 0.7895\n",
      "Epoch 154/200\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4477 - accuracy: 0.7907\n",
      "Epoch 155/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4474 - accuracy: 0.7880\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 549us/step - loss: 0.4466 - accuracy: 0.7892\n",
      "Epoch 157/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4471 - accuracy: 0.7883\n",
      "Epoch 158/200\n",
      "102/102 [==============================] - 0s 539us/step - loss: 0.4473 - accuracy: 0.7889\n",
      "Epoch 159/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4468 - accuracy: 0.7914\n",
      "Epoch 160/200\n",
      "102/102 [==============================] - 0s 618us/step - loss: 0.4469 - accuracy: 0.7892\n",
      "Epoch 161/200\n",
      "102/102 [==============================] - 0s 676us/step - loss: 0.4467 - accuracy: 0.7917\n",
      "Epoch 162/200\n",
      "102/102 [==============================] - 0s 657us/step - loss: 0.4470 - accuracy: 0.7923\n",
      "Epoch 163/200\n",
      "102/102 [==============================] - 0s 559us/step - loss: 0.4472 - accuracy: 0.7932\n",
      "Epoch 164/200\n",
      "102/102 [==============================] - 0s 569us/step - loss: 0.4476 - accuracy: 0.7907\n",
      "Epoch 165/200\n",
      "102/102 [==============================] - 0s 706us/step - loss: 0.4470 - accuracy: 0.7911\n",
      "Epoch 166/200\n",
      "102/102 [==============================] - 0s 657us/step - loss: 0.4468 - accuracy: 0.7904\n",
      "Epoch 167/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4470 - accuracy: 0.7907\n",
      "Epoch 168/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4473 - accuracy: 0.7886\n",
      "Epoch 169/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.4474 - accuracy: 0.7914\n",
      "Epoch 170/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4464 - accuracy: 0.7904\n",
      "Epoch 171/200\n",
      "102/102 [==============================] - 0s 539us/step - loss: 0.4465 - accuracy: 0.7901\n",
      "Epoch 172/200\n",
      "102/102 [==============================] - 0s 725us/step - loss: 0.4467 - accuracy: 0.7898\n",
      "Epoch 173/200\n",
      "102/102 [==============================] - 0s 657us/step - loss: 0.4466 - accuracy: 0.7892\n",
      "Epoch 174/200\n",
      "102/102 [==============================] - 0s 725us/step - loss: 0.4465 - accuracy: 0.7932\n",
      "Epoch 175/200\n",
      "102/102 [==============================] - 0s 569us/step - loss: 0.4469 - accuracy: 0.7901\n",
      "Epoch 176/200\n",
      "102/102 [==============================] - 0s 676us/step - loss: 0.4461 - accuracy: 0.7904\n",
      "Epoch 177/200\n",
      "102/102 [==============================] - 0s 608us/step - loss: 0.4470 - accuracy: 0.7907\n",
      "Epoch 178/200\n",
      "102/102 [==============================] - 0s 715us/step - loss: 0.4459 - accuracy: 0.7917\n",
      "Epoch 179/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4464 - accuracy: 0.7892\n",
      "Epoch 180/200\n",
      "102/102 [==============================] - 0s 549us/step - loss: 0.4463 - accuracy: 0.7911\n",
      "Epoch 181/200\n",
      "102/102 [==============================] - 0s 686us/step - loss: 0.4465 - accuracy: 0.7911\n",
      "Epoch 182/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4468 - accuracy: 0.7895\n",
      "Epoch 183/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4460 - accuracy: 0.7895\n",
      "Epoch 184/200\n",
      "102/102 [==============================] - 0s 618us/step - loss: 0.4463 - accuracy: 0.7886\n",
      "Epoch 185/200\n",
      "102/102 [==============================] - 0s 569us/step - loss: 0.4463 - accuracy: 0.7898\n",
      "Epoch 186/200\n",
      "102/102 [==============================] - 0s 647us/step - loss: 0.4458 - accuracy: 0.7914\n",
      "Epoch 187/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4461 - accuracy: 0.7889\n",
      "Epoch 188/200\n",
      "102/102 [==============================] - 0s 588us/step - loss: 0.4460 - accuracy: 0.7895\n",
      "Epoch 189/200\n",
      "102/102 [==============================] - 0s 579us/step - loss: 0.4463 - accuracy: 0.7935\n",
      "Epoch 190/200\n",
      "102/102 [==============================] - 0s 608us/step - loss: 0.4461 - accuracy: 0.7917\n",
      "Epoch 191/200\n",
      "102/102 [==============================] - 0s 676us/step - loss: 0.4461 - accuracy: 0.7923\n",
      "Epoch 192/200\n",
      "102/102 [==============================] - 0s 578us/step - loss: 0.4460 - accuracy: 0.7898\n",
      "Epoch 193/200\n",
      "102/102 [==============================] - 0s 627us/step - loss: 0.4462 - accuracy: 0.7898\n",
      "Epoch 194/200\n",
      "102/102 [==============================] - 0s 647us/step - loss: 0.4460 - accuracy: 0.7917\n",
      "Epoch 195/200\n",
      "102/102 [==============================] - 0s 638us/step - loss: 0.4456 - accuracy: 0.7907\n",
      "Epoch 196/200\n",
      "102/102 [==============================] - 0s 597us/step - loss: 0.4456 - accuracy: 0.7911\n",
      "Epoch 197/200\n",
      "102/102 [==============================] - 0s 637us/step - loss: 0.4468 - accuracy: 0.7901\n",
      "Epoch 198/200\n",
      "102/102 [==============================] - 0s 579us/step - loss: 0.4459 - accuracy: 0.7907\n",
      "Epoch 199/200\n",
      "102/102 [==============================] - 0s 696us/step - loss: 0.4463 - accuracy: 0.7889\n",
      "Epoch 200/200\n",
      "102/102 [==============================] - 0s 667us/step - loss: 0.4461 - accuracy: 0.7911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x278c0741bb0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train_under, y_train_under, batch_size=32,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "150844ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8c968a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1222  373]\n",
      " [  90  315]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7685"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889dd049",
   "metadata": {},
   "source": [
    "# Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ecab26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geography = 'Germany'\n",
    "credit_score = 650\n",
    "gender = 'Female'\n",
    "age = 38\n",
    "tenure = 9\n",
    "balance = 137843.23\n",
    "number_prod = 1\n",
    "cr_card = 1\n",
    "active_member = 1\n",
    "estimated_salary = 117622.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11d77c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = np.array([[credit_score, geography, gender, age, tenure, balance, number_prod, cr_card, active_member, estimated_salary]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cac3d792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['650' 'Germany' '0' '38' '9' '137843.23' '1' '1' '1' '117622.77']]\n"
     ]
    }
   ],
   "source": [
    "X_test_new[:, 2] = le.transform(X_test_new[:, 2])\n",
    "print(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01d6f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.0' '1.0' '0.0' '650' '0' '38' '9' '137843.23' '1' '1' '1'\n",
      "  '117622.77']]\n"
     ]
    }
   ],
   "source": [
    "X_test_new = ct.transform(X_test_new)\n",
    "print(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9c98aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single prediction with random forest, the customer will  leave\n"
     ]
    }
   ],
   "source": [
    "sp_forest = clf_forest.predict(sc.transform(X_test_new))\n",
    "if sp_forest == 0:\n",
    "    sp_forest = \"stay\"\n",
    "else:\n",
    "    sp_forest = \"leave\"\n",
    "print(\"Single prediction with random forest, the customer will \", sp_forest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f01dfbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single prediction with bagging, the customer will  leave\n"
     ]
    }
   ],
   "source": [
    "sp_bag = bagging.predict(sc.transform(X_test_new))\n",
    "if sp_bag == 0:\n",
    "    sp_bag = \"stay\"\n",
    "else:\n",
    "    sp_bag = \"leave\"\n",
    "print(\"Single prediction with bagging, the customer will \", sp_bag )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "893dff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single prediction with ann, the customer will  leave\n"
     ]
    }
   ],
   "source": [
    "sp_ann = ann.predict(sc.transform(X_test_new)) > 0.5\n",
    "if sp_ann == False:\n",
    "    sp_ann = \"stay\"\n",
    "else:\n",
    "    sp_ann = \"leave\"\n",
    "print(\"Single prediction with ann, the customer will \", sp_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b77faed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'France': 5014, 'Germany': 2509, 'Spain': 2477})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df['Geography']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f382a210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Male': 5457, 'Female': 4543})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df['Gender']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d860c517",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56465400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f97e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'randomforest.sav'\n",
    "filename2 = 'bag.sav'\n",
    "filename3 = 'ann.sav'\n",
    "\n",
    "pickle.dump(clf_forest, open(filename1, 'wb'))\n",
    "pickle.dump(bagging, open(filename2, 'wb'))\n",
    "\n",
    "ann_model_json = ann.to_json()\n",
    "with open(\"ann_model.json\", \"w\") as json_file:\n",
    "    json_file.write(ann_model_json)\n",
    "# serialize weights to HDF5\n",
    "ann.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4012549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ARIEFD~1\\AppData\\Local\\Temp/ipykernel_9140/4225303418.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# evaluate loaded model on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mloaded_model_ann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "json_file = open('ann_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_ann = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model_ann.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model_ann.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf845ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'randomforest.sav'\n",
    "filename2 = 'bag.sav'\n",
    "filename3 = 'ann.sav'\n",
    "\n",
    "loaded_model_rf = pickle.load(open(filename1, 'rb'))\n",
    "#result = loaded_model_rf.score(X_test, y_test)\n",
    "#print(result)\n",
    "\n",
    "loaded_model_bag = pickle.load(open(filename2, 'rb'))\n",
    "#result = loaded_model_bag.score(X_test, y_test)\n",
    "#print(result)\n",
    "\n",
    "json_file = open('ann_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_ann = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model_ann.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = loaded_model_rf.predict(sc.transform(X_test_new))\n",
    "res2 = loaded_model_bag.predict(sc.transform(X_test_new))\n",
    "res3 = loaded_model_ann.predict(sc.transform(X_test_new)) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res1)\n",
    "print(res2)\n",
    "print(res3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
